{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text-preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNwKSc/oFHDzmKel1wSkQqZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"zmr1gwC86VFt"},"source":["!pip3 install transformers sentencepiece pandas gensim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"08f_myr26eVX"},"source":["import pandas as pd \n","import numpy as np \n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","import gc\n","import gensim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_wb7h0k6exZ"},"source":["cols = ['item_id', 'title', 'description']\n","text_cols = ['title', 'description']\n","data_chunks = pd.read_csv('/storage/data/simple_features.csv', chunksize=100000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OtRXH-dD6hzs"},"source":["tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n","model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n","model.cuda()  # uncomment it if you have a GPU\n","\n","def embed_bert_cls(text):\n","    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n","    with torch.no_grad():\n","        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n","    embeddings = model_output[-2][:, 0, :]\n","    embeddings = torch.nn.functional.normalize(embeddings)\n","    return embeddings[0].cpu().numpy()\n","\n","doc2vec_models = {col: gensim.models.Doc2Vec.load('/storage/data/doc2vec_{}'.format(col)) for col in text_cols}\n","\n","for i, data in enumerate(data_chunks):\n","  data = data[cols].fillna('продать')\n","  for col in text_cols:\n","      texts = data[col].tolist()\n","      bert_embeds = [embed_bert_cls(str(text)) for text in texts]\n","      doc2vec_embeds = [doc2vec_models[col].infer_vector(gensim.utils.simple_preprocess(str(text))) for text in texts]\n","      data = pd.concat([data, \n","                        pd.DataFrame(bert_embeds, columns=['{}_mbert_{}'.format(col, i) for i in range(len(bert_embeds[0]))]),\n","                        pd.DataFrame(doc2vec_embeds, columns=['{}_doc2vec_{}'.format(col, i) for i in range(len(doc2vec_embeds[0]))])], axis=1)\n","      texts, bert_embeds, doc2vec_embeds = None, None, None\n","      gc.collect()\n","  data = data.drop(text_cols, axis=1)\n","  data.to_csv('/storage/data/text_train.csv',\n","                  header = True if i == 0 else False, index=False,\n","                  mode = 'w' if i == 0 else 'a')\n","  data = None\n","  gc.collect()"],"execution_count":null,"outputs":[]}]}