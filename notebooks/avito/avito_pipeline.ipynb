{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"avito_pipeline.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1_allu-WkIXygzJIld61GCiqpy8Xopy5R","authorship_tag":"ABX9TyNLZO+idENembXdNwYdzK/2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqwjnfXEEEsI","executionInfo":{"status":"ok","timestamp":1638531613186,"user_tz":-180,"elapsed":3353,"user":{"displayName":"Данил Ельцов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01985227269587903507"}},"outputId":"1d3c743f-6830-41d8-a8c7-3388fb2a0121"},"source":["!cp -f /content/drive/MyDrive/ml/utils/utils.py ./\n","!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n","!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n","!mkdir -p /root/.local/bin\n","!cp -f mystem /root/.local/bin/mystem"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-12-03 11:40:09--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n","Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.241, 5.45.205.244, 5.45.205.245, ...\n","Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.241|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: http://cache-man01i.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz [following]\n","--2021-12-03 11:40:10--  http://cache-man01i.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n","Resolving cache-man01i.cdn.yandex.net (cache-man01i.cdn.yandex.net)... 5.45.205.221, 2a02:6b8::3:221\n","Connecting to cache-man01i.cdn.yandex.net (cache-man01i.cdn.yandex.net)|5.45.205.221|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 16457938 (16M) [application/octet-stream]\n","Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz.2’\n","\n","mystem-3.0-linux3.1 100%[===================>]  15.70M  9.81MB/s    in 1.6s    \n","\n","2021-12-03 11:40:12 (9.81 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz.2’ saved [16457938/16457938]\n","\n","mystem\n"]}]},{"cell_type":"code","metadata":{"id":"34CUrLaJE_gT"},"source":["!pip3 install "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"epjZUJ8rD9BO","executionInfo":{"status":"ok","timestamp":1638532587654,"user_tz":-180,"elapsed":237,"user":{"displayName":"Данил Ельцов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01985227269587903507"}}},"source":["import gc\n","import glob\n","import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","\n","from utils import *"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"uLMO677wFYoQ","executionInfo":{"status":"ok","timestamp":1638531702080,"user_tz":-180,"elapsed":227,"user":{"displayName":"Данил Ельцов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01985227269587903507"}}},"source":["# paths\n","ROOT, ROOT_DATA, ROOT_MODELS, ROOT_GRAPHS, ROOT_IMAGES = get_default_paths('/content/drive/MyDrive/ml/hacks/avito')\n","\n","# images\n","IMG_HEIGHT, IMG_WIDTH = 224, 224\n","image_batch_size = 100\n","model_link = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n","image_prefix = \"image_\"\n","\n","# text\n","title_batch_size = 10000\n","title_vector_size = 100\n","title_window_size = 5\n","description_batch_size = 10000\n","description_vector_size = 300\n","description_window_size = 10\n","bert_prefix = \"bert_\"\n","doc2vec_prefix = \"doc2vec_\"\n","doc2vec_workers = 2\n","doc2vec_epochs = 30\n","\n","# tabnet\n","tabnet_batch_size = 1000\n","tabnet_shuffle_size = 10000\n","tabnet_epochs = 15\n","tabnet_lr = 1e-4\n","tabnet_layers = 5\n","tabnet_steps_epoch = 10000\n","tabnet_valid_steps = 1000\n","tabnet_feature_relaxation = 1.2\n","tabnet_sparsity_coeff = 1e-3\n","tabnet_batch_momentum = 0.8\n","tabnet_virtual_batch_size = 250\n","tabnet_feature_dim = 64\n","tabnet_output_dim = 32\n","\n","# general\n","train_size = int(1.5e6)\n","valid_size = train_size * 0.3\n","batch_size = 10000\n","categorical_threshold = 100\n","\n","# columns\n","categorical_columns = ['region', 'city', 'parent_category_name', 'category_name', 'param_1', 'param_2', 'param_3',\n","                       'user_type', 'item_seq_number']\n","gen_categorical_columns = [col + \"_\" for col in categorical_columns]\n","numerical_columns = ['image_top_1', 'price']\n","gen_numerical_columns = ['price_mean', 'price_std']\n","text_columns = ['title', 'description']\n","meta_columns = ['item_id', 'user_id', 'image', 'activation_date']\n","label = 'deal_probability'\n","feature_columns = numerical_columns + gen_numerical_columns + categorical_columns + gen_categorical_columns \\\n","                  + [bert_prefix, doc2vec_prefix, image_prefix]\n","\n","# set pretty output for pandas dataframes\n","prettify_pandas_print()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"A4laoZjVFW8C","executionInfo":{"status":"error","timestamp":1638532618447,"user_tz":-180,"elapsed":28705,"user":{"displayName":"Данил Ельцов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01985227269587903507"}},"outputId":"167e6f04-b7ae-430f-afd8-a8673744226e"},"source":["def make_features():\n","    # load train data and sort it for avoiding future leak\n","    train = pd.read_csv(f'{ROOT_DATA}/train.csv').sort_values('activation_date')\n","    train['is_train'] = '1'\n","\n","    test = pd.read_csv(f'{ROOT_DATA}/test.csv')\n","    test['is_train'] = '0'\n","\n","    df = pd.concat([train, test], axis=0)\n","\n","    # price has lognormal distribution\n","    df = log_scale(df, 'price', 0, 1e6)\n","    df = fill_mean_by(df, 'price', 'parent_category_name', drop_mean=False)\n","    df = add_std_by(df, 'price', 'parent_category_name')\n","    df = fill_value(df, 'image_top_1', 0)\n","\n","    # clean and lemmatize russian text\n","    df = process_russian_cols(df, text_columns)\n","\n","    # create ohe for category\n","    for col in categorical_columns:\n","        df = ohe_col_with_threshold(df, col, categorical_threshold)\n","\n","    df[df['is_train'] == '1'].to_csv(f'{ROOT_DATA}/train_features.csv', index=False, header=True)\n","    df[df['is_train'] == '0'].to_csv(f'{ROOT_DATA}/test_features.csv', index=False, header=True)\n","\n","    del df\n","    gc.collect()\n","\n","\n","# making base features for train/test\n","make_features()"],"execution_count":17,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: 'pandas._libs.index.IndexEngine._call_map_locations'\n","Traceback (most recent call last):\n","  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1709, in pandas._libs.hashtable.PyObjectHashTable.map_locations\n","TypeError: unhashable type: 'list'\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mintersection\u001b[0;34m(self, other, sort)\u001b[0m\n\u001b[1;32m   2677\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2678\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2679\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2989\u001b[0m             raise InvalidIndexError(\n\u001b[0;32m-> 2990\u001b[0;31m                 \u001b[0;34m\"Reindexing only valid with uniquely valued Index objects\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2991\u001b[0m             )\n","\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: 'pandas._libs.index.IndexEngine._call_map_locations'\n","Traceback (most recent call last):\n","  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1709, in pandas._libs.hashtable.PyObjectHashTable.map_locations\n","TypeError: unhashable type: 'list'\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mintersection\u001b[0;34m(self, other, sort)\u001b[0m\n\u001b[1;32m   2677\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2678\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2679\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2989\u001b[0m             raise InvalidIndexError(\n\u001b[0;32m-> 2990\u001b[0;31m                 \u001b[0;34m\"Reindexing only valid with uniquely valued Index objects\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2991\u001b[0m             )\n","\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-6ffd4ac52098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# making base features for train/test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmake_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-6ffd4ac52098>\u001b[0m in \u001b[0;36mmake_features\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# price has lognormal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_mean_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parent_category_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_std_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parent_category_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'image_top_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mfill_mean_by\u001b[0;34m(df, col, by, drop_mean)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# fill empty column values by mean grouping with by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfill_mean_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mmean_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_mean_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}_mean'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36madd_mean_by\u001b[0;34m(df, col, by)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mmean_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mmean_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'{}_mean'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7961\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7962\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7963\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7964\u001b[0m         )\n\u001b[1;32m   7965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_specification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# note this function has side effects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_validate_specification\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0mleft_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0mright_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m                 \u001b[0mcommon_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_cols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m                     raise MergeError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mintersection\u001b[0;34m(self, other, sort)\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# InvalidIndexError raised by get_indexer if non-unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m             \u001b[0;31m# IncompatibleFrequency raised by PeriodIndex.get_indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2683\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2684\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer_non_unique\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   4698\u001b[0m             \u001b[0mtgt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_engine_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4700\u001b[0;31m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer_non_unique\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"]}]},{"cell_type":"code","metadata":{"id":"xeeYsH-MFUtk"},"source":["# preparing for text\n","def get_chunks(name):\n","    return pd.read_csv(f'{ROOT_DATA}/{name}_features.csv', chunksize=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NvgF0JbKFOlx"},"source":["build_doc2vec(df=get_chunks('train'), col='title', chunked=True, fill_na='продать', workers=doc2vec_workers,\n","              tmp_path=ROOT_MODELS, vector_size=title_vector_size, window_size=title_window_size, epochs=doc2vec_epochs)\n","build_doc2vec(df=get_chunks('train'), col='description', chunked=True, fill_na='продать', workers=doc2vec_workers,\n","              tmp_path=ROOT_MODELS, vector_size=description_vector_size, window_size=description_window_size,\n","              epochs=doc2vec_epochs)\n","\n","bert_model, bert_tokenizer = get_tiny_bert_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvsL64Y3FMwc"},"source":["# preparing for images\n","create_empty_image(IMG_WIDTH, IMG_HEIGHT, f\"{ROOT_IMAGES}/empty.jpg\")\n","image_paths = {image_path.split(\"/\")[-1].replace(\".jpg\", \"\"): image_path for image_path in\n","               glob.glob(f\"{ROOT_IMAGES}/*.jpg\")}\n","image_model = create_image_model(IMG_HEIGHT, IMG_WIDTH, model_link)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QlQYaGARFJtx"},"source":["def add_embeddings(name):\n","    first_valid = True\n","    for i, chunk in enumerate(get_chunks(name)):\n","        chunk = add_tiny_bert_embeds(chunk, 'title', fillna='продать', model=bert_model, tokenizer=bert_tokenizer,\n","                                     pref=bert_prefix)\n","        chunk = add_doc2vec_embeds(chunk, 'title', fillna='продать', model_path=f'{ROOT_MODELS}/doc2vec_title',\n","                                   pref=doc2vec_prefix)\n","        chunk = add_tiny_bert_embeds(chunk, 'description', fillna='продать', model=bert_model, tokenizer=bert_tokenizer,\n","                                     pref=bert_prefix)\n","        chunk = add_doc2vec_embeds(chunk, 'description', fillna='продать',\n","                                   model_path=f'{ROOT_MODELS}/doc2vec_description',\n","                                   pref=doc2vec_prefix)\n","        chunk = images_embedding(chunk, 'image', paths=image_paths, w=IMG_HEIGHT, h=IMG_WIDTH, model=image_model,\n","                                 pref=image_prefix, batch_size=image_batch_size)\n","\n","        is_valid = i * chunk >= (train_size - valid_size) and name != 'test'\n","        header = (i == 0) or (is_valid and first_valid)\n","        mode = 'w' if (i == 0) or (is_valid and first_valid) else 'a'\n","\n","        if is_valid and first_valid:\n","            first_valid = False\n","\n","        if not is_valid:\n","            chunk.to_csv(f'{ROOT_DATA}/{name}_dataset.csv', index=False, header=header, mode=mode)\n","        else:\n","            chunk.to_csv(f'{ROOT_DATA}/valid_dataset.csv', index=False, header=header, mode=mode)\n","\n","\n","add_embeddings('train')\n","add_embeddings('test')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-25gKLfMFFG_"},"source":["def create_tabnet_model(feature_columns):\n","    import tensorflow as tf\n","    import tabnet\n","    train = get_tensorflow_dataset(f'{ROOT_DATA}/train_dataset.csv', batch_size=tabnet_batch_size,\n","                                   label=label,\n","                                   feature_columns=feature_columns,\n","                                   shuffle_buffer_size=tabnet_shuffle_size).prefetch(10)\n","    valid = get_tensorflow_dataset(f'{ROOT_DATA}/valid_dataset.csv', batch_size=tabnet_batch_size,\n","                                   label=label,\n","                                   feature_columns=feature_columns,\n","                                   shuffle_buffer_size=tabnet_shuffle_size).prefetch(10)\n","    # Use Group Normalization for small batch sizes\n","    model = tabnet.TabNetRegressor(feature_columns=None,\n","                                   num_regressors=1,\n","                                   num_decision_steps=tabnet_layers,\n","                                   relaxation_factor=tabnet_feature_relaxation,\n","                                   sparsity_coefficient=tabnet_sparsity_coeff,\n","                                   batch_momentum=tabnet_batch_momentum,\n","                                   virtual_batch_size=tabnet_virtual_batch_size,\n","                                   feature_dim=tabnet_feature_dim,\n","                                   output_dim=tabnet_output_dim)\n","\n","    lr = tf.keras.optimizers.schedules.ExponentialDecay(tabnet_lr, decay_steps=2000, decay_rate=0.95, staircase=False)\n","    optimizer = tf.keras.optimizers.Adam(lr)\n","    model.compile(optimizer, loss='mse', metrics=['mse', 'mae'])\n","\n","    model.fit(train, epochs=tabnet_epochs, validation_data=valid, verbose=True, steps_per_epoch=tabnet_steps_epoch,\n","              validation_steps=tabnet_valid_steps)\n","\n","    model.summary()\n","\n","    return model\n","\n","\n","tabnet_model = create_tabnet_model(feature_columns)\n","tabnet_model.save(f'{ROOT_MODELS}/tabnet')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QGQ4p2JUFDWm"},"source":["import tensorflow as tf\n","import pandas as pd\n","\n","test_chunks = pd.read_csv(f'{ROOT_DATA}/test_dataset.csv', chunksize=batch_size)\n","for i, test_chunk in enumerate(test_chunks):\n","    features = [col for col in test_chunk.columns if col.startswith(feature_columns)]\n","    test_chunk[label] = pd.Series(tabnet_model(tf.convert_to_tensor(test_chunks[features].values)).numpy())\n","    test_chunks[['item_id', label]].to_csv(f'{ROOT_DATA}/tabnet_submission.csv', index=False, header=i == 0,\n","                                           mode='w' if i == 0 else 'a')"],"execution_count":null,"outputs":[]}]}